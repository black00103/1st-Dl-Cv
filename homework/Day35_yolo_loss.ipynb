{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "piG8kRMgbFTz"
   },
   "source": [
    "## ç¯„ä¾‹\n",
    "YOLO çš„ç¶²è·¯è¼¸å‡ºæ˜¯ä¸€å€‹ 7x7x30 çš„ tensor,\n",
    "\n",
    "è€Œä»Šå¤©çš„ç¨‹å¼ç¢¼ç¯„ä¾‹çš„ç›®æ¨™æ˜¯è®“å¤§å®¶ç”±ç¨‹å¼ç¢¼å¯¦ç¾æå¤±å‡½æ•¸çš„è¨ˆç®—ï¼Œé€éæå¤±å‡½æ•¸è¡¡é‡ä¸€å¼µåœ–ç‰‡ç¶“ç”± YOLO æ¨¡å‹è¾¨è­˜å¾Œçš„çµæœå’Œæ¨™è¨˜æª”çš„å·®è·æœ‰å¤šé ã€‚\n",
    "ä»Šå¤©çš„ç¯„ä¾‹ï¼Œæ¡ç”¨çš„æ˜¯YOLOv1_tinyçš„ç¶²çµ¡ã€‚\n",
    "\n",
    "è³‡æ–™ä¾†æº: https://github.com/solaris33/dl_cv_tensorflow_10weeks/blob/master/week10/tensorflow-yolo/yolo/net/yolo_net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5agKBc5MbFT2"
   },
   "source": [
    "è¼¸å…¥æ‰€éœ€çš„libraryï¼Œé€™é‚Šæœƒå‘¼å«åˆ°å…¶ä»–çš„ç¨‹å¼ç¢¼(YoloTinyNet.py)ï¼Œ\n",
    "é æ¸¬çš„é¡å‹(classes_name)å…±æœ‰20ç¨®ã€‚\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘å€‘å…ˆé–‹ä¸€å€‹\"Day35.YOLO ç´°ç¯€ç†è§£ - æå¤±å‡½æ•¸ç¨‹å¼ç¢¼è§£è®€\"çš„googleé›²ç«¯ç©ºé–“è³‡æ–™å¤¾ï¼Œ\n",
    "æŠŠç³»çµ±çš„ç¨‹å¼ç¢¼ä¸Šå‚³åˆ°é€™å€‹è³‡æ–™å¤¾ä¸­ã€‚\n",
    "ä¸‹é¢ç¨‹å¼ç¢¼ï¼Œæˆ‘å€‘å…ˆæŠŠgoogleçš„é›²ç«¯ç¡¬ç¢Ÿé€£çµåˆ°colabä¸Šï¼Œåœ¨ä½¿ç”¨pythonå°‡å·¥ä½œè·¯å¾‘åˆ‡æ›åˆ°ä½ æƒ³è¦çš„æ–‡ä»¶å¤¾ï¼Œå°±å¯ä»¥åœ¨colabä¸Šé‹è¡Œpythonä¸¦æŠ“å–åˆ°ç›¸å°çš„æª”æ¡ˆã€‚\n",
    "\n",
    "é¦–å…ˆåŸ·è¡Œç¨‹å¼å¾Œï¼Œä¸‹æ–¹æœƒè·³å‡ºä¸€å€‹è¶…é€£çµï¼Œ\n",
    "1.   é»é¸ä½ çš„googleå¸³è™Ÿ\n",
    "2.   é»é¸å…è¨±colabèƒ½æ“ä½œä½ çš„é›²ç«¯ç¡¬ç¢Ÿï¼Œ\n",
    "3.   è·³å‡ºå¦ä¸€å€‹ç•«é¢ï¼Œé»å³é‚Šçš„å°æ–¹æ ¼ï¼Œè¤‡è£½é€£çµï¼Œ\n",
    "4.   è²¼åˆ°Enter your authorization code:ä¸‹æ–¹çš„å°æ¡†æ¡†ï¼ŒæŒ‰ä¸‹enterã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7yCo2N5b3D5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom google.colab import drive\\ndrive.mount(\\'/content/drive\\')\\n# æŒ‡å®šgoogle driveé›²ç«¯ç¡¬ç¢Ÿçš„è·Ÿç›®éŒ„ï¼Œåç‚ºdrive\\n#!mkdir -p drive\\n#!google-drive-ocamlfuse drive\\n\\nimport os\\n# æ­¤è™•ç‚ºgoogle driveä¸­çš„æ–‡ä»¶è·¯å¾‘ï¼Œdriveç‚ºä¹‹å‰æŒ‡å®šçš„å·¥ä½œè·Ÿç›®éŒ„ï¼Œè¦åŠ ä¸Šä½ç½®\\n# å¦‚æœå­˜æ”¾çš„è·¯å¾‘æœ‰è®Šï¼Œå¾/content/drive/My Drive/XXXXX...åšèª¿æ•´\\npath = \"Day35\"\\nos.chdir(path)\\n\\n!ls\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# æŒ‡å®šgoogle driveé›²ç«¯ç¡¬ç¢Ÿçš„è·Ÿç›®éŒ„ï¼Œåç‚ºdrive\n",
    "#!mkdir -p drive\n",
    "#!google-drive-ocamlfuse drive\n",
    "\n",
    "import os\n",
    "# æ­¤è™•ç‚ºgoogle driveä¸­çš„æ–‡ä»¶è·¯å¾‘ï¼Œdriveç‚ºä¹‹å‰æŒ‡å®šçš„å·¥ä½œè·Ÿç›®éŒ„ï¼Œè¦åŠ ä¸Šä½ç½®\n",
    "# å¦‚æœå­˜æ”¾çš„è·¯å¾‘æœ‰è®Šï¼Œå¾/content/drive/My Drive/XXXXX...åšèª¿æ•´\n",
    "path = \"Day35\"\n",
    "os.chdir(path)\n",
    "!ls\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5319,
     "status": "ok",
     "timestamp": 1578970921448,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "pvdtB3HE7gJx",
    "outputId": "f4fd899e-1fa5-4cd5-c14f-555a4e2ce3a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' ä¸æ˜¯å…§éƒ¨æˆ–å¤–éƒ¨å‘½ä»¤ã€å¯åŸ·è¡Œçš„ç¨‹å¼æˆ–æ‰¹æ¬¡æª”ã€‚\n"
     ]
    }
   ],
   "source": [
    "#!ls yolo/net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5303,
     "status": "ok",
     "timestamp": 1578970921451,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "xE6PP2af46a_",
    "outputId": "439a87ab-f44f-4e09-e3b9-81aee95c0464"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yolo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c8c909aa30f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yolo/net'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#Now we can import the library and use the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0myolo_tiny_net\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mYoloTinyNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m#%tensorflow_version 1.x # ç¢ºä¿ colob ä¸­ä½¿ç”¨çš„ tensorflow æ˜¯ 1.x ç‰ˆæœ¬è€Œä¸æ˜¯ tensorflow 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\D35\\yolo_tiny_net.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mYoloTinyNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yolo'"
     ]
    }
   ],
   "source": [
    "#We'll need to update our path to import from Drive.\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = \"Day35\"\n",
    "#sys.path.append(os.path.join(path, \"yolo/net\"))\n",
    "#os.chdir(path)\n",
    "sys.path.append('yolo/net')\n",
    "#Now we can import the library and use the function.\n",
    "from yolo_tiny_net import YoloTinyNet \n",
    "#%tensorflow_version 1.x # ç¢ºä¿ colob ä¸­ä½¿ç”¨çš„ tensorflow æ˜¯ 1.x ç‰ˆæœ¬è€Œä¸æ˜¯ tensorflow 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5292,
     "status": "ok",
     "timestamp": 1578970921452,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "aW4kXKVJJPOZ",
    "outputId": "b67c9ba7-5192-41b7-89c1-57e63eadbb2b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "if not os.path.exists(\"Day35.YOLO ç´°ç¯€ç†è§£ - æå¤±å‡½æ•¸/models/pretrain/yolo_tiny.ckpt\"):\n",
    "  # ä¸‹è¼‰ yolo_tiny çš„ç¶²è·¯æ¬Šé‡\n",
    "  print(\"Model doesn't exist, downloading...\")\n",
    "  os.system(\"wget https://drive.google.com/file/d/0B-yiAeTLLamRekxqVE01Yi1RRlk/view?usp=sharing\")\n",
    "#  print(\"Converting yolov3.weights to yolo.h5...\")\n",
    "#  os.system(\"python convert.py yolov3.cfg yolov3.weights models/pretrain/yolo_tiny.ckpt\")\n",
    "else:\n",
    "  print(\"Model exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Z5rqCiCbFT4"
   },
   "outputs": [],
   "source": [
    "#from yolo.net.yolo_tiny_net import YoloTinyNet \n",
    "#from yolo import YOLO # å¾ yolo.py ä¸­å°‡è©²é …ç›®å®šç¾©çš„ YOLO class è¼‰å…¥ï¼Œå…¶è©³ç´°å®šç¾©è«‹åƒè€ƒ yolo.py\n",
    "import tensorflow as tf \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "tf.reset_default_graph() #é¿å…Pythonçš„æ§åˆ¶æª¯æœƒå„²å­˜ä¸Šæ¬¡åŸ·è¡ŒçµæŸçš„è®Šæ•¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APeoGwejbFT_"
   },
   "source": [
    "è®€å…¥è³‡æ–™é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8440,
     "status": "ok",
     "timestamp": 1578970924621,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "-quWCGQlbFUA",
    "outputId": "16256fc1-f4b2-4fbb-e065-0d65e285baf1"
   },
   "outputs": [],
   "source": [
    "# ä¸‹è¼‰åœ–ç‰‡ç¯„ä¾‹ï¼Œå¦‚æœå·²ç¶“ä¸‹è¼‰éå°±å¯ä»¥è¨»è§£æ‰\n",
    "#!wget https://github.com/pjreddie/darknet/blob/master/data/dog.jpg?raw=true -O dog.jpg\n",
    "img = cv2.imread(\"dog.jpg\") # è®€å–ç¯„ä¾‹åœ–ç‰‡\n",
    "h, w, _ = img.shape\n",
    "print(img.shape)\n",
    "def show(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # plt.imshow é è¨­åœ–ç‰‡æ˜¯ rgb çš„\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8430,
     "status": "ok",
     "timestamp": 1578970924622,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "VQ_hvwU3bFUE",
    "outputId": "7dd97453-44d4-4fcc-d4ae-751e8b973284"
   },
   "outputs": [],
   "source": [
    "boxes = np.array([[128, 224, 314, 537], [475, 85, 689, 170], [162, 119, 565, 441]]).astype(float)\n",
    "# æŠŠ bboxes åæ¨™ä»¥åŸåœ–çš„ resolution normalize åˆ° 0~1 ä¹‹é–“\n",
    "boxes[:, [0, 2]] = boxes[:, [0, 2]] / img.shape[1]\n",
    "boxes[:, [1, 3]] = boxes[:, [1, 3]] / img.shape[0]\n",
    "\n",
    "img_show = img.copy()\n",
    "for x1, y1, x2, y2 in boxes:\n",
    "    cv2.rectangle(img_show, (int(x1*w), int(y1*h)), (int(x2*w), int(y2*h)), (0, 255, 0), 2)\n",
    "show(img_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9280,
     "status": "ok",
     "timestamp": 1578970925487,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "IdeZ69vachDL",
    "outputId": "e543a709-7e54-4415-f320-1a255eec3d43"
   },
   "outputs": [],
   "source": [
    "#æ¨¡æ“¬å½±åƒçš„æ¨™è¨˜æª”çµæœ\n",
    "# yoloè¼¸å…¥çš„æ˜¯448*448ï¼Œæ‰€ä»¥åŸå§‹å¤§å°è¦å…ˆç¸®æˆ448*448ï¼Œæ‰€ä»¥åŸæœ¬çš„æ¨™è¨˜æ¡†å¤§å°ä¹Ÿè¦å°æ‡‰è½‰æ›\n",
    "dy=448/576\n",
    "dx=448/768\n",
    "boxes = np.array([[128*dx, 224*dy, 314*dx, 537*dy], [475*dx, 85*dy, 689*dx, 170*dy], [162*dx, 119*dy, 565*dx, 441*dy]]).astype(float)\n",
    "np_img = cv2.imread('dog.jpg')\n",
    "resized_img = cv2.resize(np_img, (448, 448))\n",
    "img_show = resized_img.copy()\n",
    "for x1, y1, x2, y2 in boxes:\n",
    "    cv2.rectangle(img_show, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "show(img_show)\n",
    "print(boxes[0,])\n",
    "print(boxes[1,])\n",
    "print(boxes[2,])\n",
    "#å¯ä»¥æª¢è¦–ä¸€ä¸‹ï¼Œè½‰æ›å¾Œæ¨™è¨˜çš„çµæœçš„ç¢ºèƒ½æ¡†ä½ç‰©é«”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9267,
     "status": "ok",
     "timestamp": 1578970925489,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "qwkNKZiwfF0Q",
    "outputId": "a88ca3a9-183c-421a-876f-472bc19d1d56"
   },
   "outputs": [],
   "source": [
    "#æ¨™è¨˜æª”: labelsè½‰æˆ loss å‡½æ•¸æ‰€éœ€çš„æ ¼å¼,(xmin,ymin,xmax,ymax)-->(x_center, y_center, w, h,class) in (448,448)\n",
    "labels = np.zeros((3, 5)) \n",
    "#labels [0,0:4]=boxes[0,]\n",
    "#labels [1,0:4]=boxes[1,]\n",
    "#labels [2,0:4]=boxes[2,]\n",
    "\n",
    "#print(labels)\n",
    "labels [:,0]=(boxes[:,0]+boxes[:,2])/2\n",
    "labels [:,1]=(boxes[:,1]+boxes[:,3])/2\n",
    "\n",
    "labels [:,2]=boxes[:,2]-boxes[:,0]\n",
    "labels [:,3]=boxes[:,3]-boxes[:,1]\n",
    "\n",
    "\n",
    "labels [0,4]=6\n",
    "labels [1,4]=1\n",
    "labels [2,4]=11\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9233,
     "status": "ok",
     "timestamp": 1578970925490,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "l13_M-_PftRK",
    "outputId": "4e38e784-c724-4d42-88ed-60a89d2a16d1"
   },
   "outputs": [],
   "source": [
    "print(labels)\n",
    "labels = tf.reshape(labels, (3, 5))\n",
    "labels = tf.cast(labels, tf.float32) \n",
    "#ç‚ºäº†å¾ŒçºŒé‹ç®—è½‰æˆ float32\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VI3E-EEibFUH"
   },
   "outputs": [],
   "source": [
    "#è¼¸å‡ºå±¤è§£ç¢¼\n",
    "def process_predicts(predicts):\n",
    "  #é¡åˆ¥\n",
    "  p_classes = predicts[0, :, :, 0:20]\n",
    "  #å€‹åˆ¥bboxåŒ…å«æœ‰ç‰©ä»¶çš„æ©Ÿç‡\n",
    "  C = predicts[0, :, :, 20:22]\n",
    "  #å€‹åˆ¥bboxçš„æ¨™è¨˜æ¡†ä½ç½®\n",
    "  coordinate = predicts[0, :, :, 22:]\n",
    "\n",
    "  p_classes = np.reshape(p_classes, (7, 7, 1, 20))\n",
    "  C = np.reshape(C, (7, 7, 2, 1))\n",
    "\n",
    "  #å°æ‡‰ç›¸ä¹˜ï¼Œç”¢ç”Ÿğ‘(ã€–ğ¶ğ‘™ğ‘ğ‘ ğ‘ ã€—_ğ‘— |ğ‘œğ‘ğ‘—ğ‘’ğ‘ğ‘¡)*ğ‘ƒ(ğ‘œğ‘ğ‘—ğ‘’ğ‘ğ‘¡)\n",
    "  P = C * p_classes\n",
    "\n",
    "  index = np.argmax(P) #è¿”é‚„æœ€å¤§å€¼ç´¢å¼•(486)\n",
    "  #print(index) #486\n",
    "  index = np.unravel_index(index, P.shape)#(7, 7, 1, 20)\n",
    "  #print(index) #(1, 5, 0, 6)\n",
    "\n",
    "  class_num = index[3]\n",
    "\n",
    "  coordinate = np.reshape(coordinate, (7, 7, 2, 4))\n",
    "\n",
    "  max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "  xcenter = max_coordinate[0]\n",
    "  #print(\"xcenter=\",xcenter)\n",
    "  ycenter = max_coordinate[1]\n",
    "  #print(\"ycenter=\",ycenter)\n",
    "  w = max_coordinate[2]\n",
    "  #print(\"w=\",w)\n",
    "  h = max_coordinate[3]\n",
    "  #print(\"h=\",h)\n",
    "  \n",
    "  #index[1] : x ç¶²æ ¼ä½ç½®\n",
    "  xcenter = (index[1] + xcenter) * (448/7.0)\n",
    "  # index[0]: yç¶²æ ¼ä½ç½®\n",
    "  ycenter = (index[0] + ycenter) * (448/7.0)\n",
    "\n",
    "  w = w * 448\n",
    "  h = h * 448\n",
    "\n",
    "  xmin = xcenter - w/2.0\n",
    "  ymin = ycenter - h/2.0\n",
    "\n",
    "  xmax = xmin + w\n",
    "  ymax = ymin + h\n",
    "\n",
    "  return xmin, ymin, xmax, ymax, class_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIZxrGwUbFUM"
   },
   "source": [
    "### è¨­å®šYoloTinyNet \n",
    "é€éYoloTinyNetç”¢ç”Ÿä¸€å€‹é æ¸¬çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9xIMzgFbFUN"
   },
   "outputs": [],
   "source": [
    "common_params = {'image_size': 448, 'num_classes': 20, \n",
    "                'batch_size':1}\n",
    "net_params = {'cell_size': 7, 'boxes_per_cell':2, 'weight_decay': 0.0005, 'class_scale': 2.0,\n",
    "'object_scale':1.0, 'noobject_scale': 0.5, 'coord_scale': 5.0}\n",
    "\n",
    "net = YoloTinyNet(common_params, net_params, test=False)\n",
    "#net = YoloNet(common_params, net_params, test=True)\n",
    "\n",
    "# Tensorflow å¦‚æœæƒ³è¦å¾å¤–éƒ¨å‚³å…¥data,é‚£å°±è¦ç”¨åˆ° tf.placeholder()ï¼Œç„¶å¾Œä»¥é€™ç¨®å½¢å¼å‚³è¼¸æ•¸æ“šï¼Œ sess.run(***,feed_dict={input: **})\n",
    "# å‚³å€¼çš„å·¥ä½œäº¤çµ¦ sess.run(),éœ€è¦å‚³å…¥çš„å€¼æ”¾åœ¨ feed_dict={}ï¼Œä¸€ä¸€å°æ‡‰æ¯ä¸€å€‹ input, placeholderå’Œ feed_dict={}æ˜¯ç¶å®šåœ¨ä¸€å‡ºç¾çš„ã€‚ \n",
    "image = tf.placeholder(tf.float32, (1, 448, 448, 3))\n",
    "predicts = net.inference(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9587,
     "status": "ok",
     "timestamp": 1578970925927,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "p2RUlgT0bFUS",
    "outputId": "21fa98d9-36da-4540-c2dd-984403c8aebc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Session æ˜¯ Tensorflow é–‹å•Ÿä¸€å€‹å°è©±ï¼ŒåŸ·è¡Œè¼¸å‡ºçµæœã€‚\n",
    "sess = tf.Session()\n",
    "np_img = cv2.imread('dog.jpg')\n",
    "resized_img = cv2.resize(np_img, (448, 448))\n",
    "np_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "np_img = np_img.astype(np.float32)\n",
    "\n",
    "np_img = np_img / 255.0 * 2 - 1\n",
    "np_img = np.reshape(np_img, (1, 448, 448, 3))\n",
    "\n",
    "#ä¸€äº›è¨­å®šçš„å‡½æ•¸ï¼Œå…ˆè·³éã€‚\n",
    "saver = tf.train.Saver(net.trainable_collection)\n",
    "#è¼¸å…¥ç¶²çµ¡æ¶æ§‹çš„åƒæ•¸æª”\n",
    "saver.restore(sess, 'models/pretrain/yolo_tiny.ckpt')\n",
    "#é–‹å•Ÿå°è©±ï¼Œé€²è¡Œé æ¸¬\n",
    "np_predict = sess.run(predicts, feed_dict={image: np_img})\n",
    "print(np_predict.shape)\n",
    "print(np_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BYiq-kKEbFUX"
   },
   "source": [
    "### é æ¸¬å‡ºä¾†ç”¢ç”Ÿçš„çµæœæª”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9564,
     "status": "ok",
     "timestamp": 1578970925928,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "gGzfeXuobFUY",
    "outputId": "4c6d949d-31ea-4659-9297-1ebde6fe5ba6"
   },
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax, class_num = process_predicts(np_predict)\n",
    "print(\"output\")\n",
    "print(xmin)\n",
    "print(ymin)\n",
    "print(xmax)\n",
    "print(ymax)\n",
    "print(class_num) #\"car\"\n",
    "class_name = classes_name[class_num]\n",
    "print(class_name)\n",
    "#ç•«å‡ºå°æ‡‰æ¡†\n",
    "cv2.rectangle(resized_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 0, 255))\n",
    "cv2.putText(resized_img, class_name, (int(xmin), int(ymin)), 2, 1.5, (0, 0, 255))\n",
    "#çµæœè¼¸å‡º\n",
    "cv2.imwrite('dog_out.jpg', resized_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wUS-ZPoNbVmj"
   },
   "source": [
    "å¯ä»¥çœ‹ä¸€ä¸‹é›²ç«¯ç¡¬ç¢Ÿçš„ç©ºé–“è£¡æœ‰æ²’æœ‰å¤šä¸€å¼µdog_out.jpgï¼Œ\n",
    "æ¥ä¸‹ä¾†æˆ‘å€‘é€éä¸‰å€‹å‡½æ•¸ï¼Œè¨ˆç®—ä¸€å¼µåœ–ç‰‡ç¶“ç”± YOLO æ¨¡å‹è¾¨è­˜å¾Œçš„çµæœå’Œæ¨™è¨˜æª”çš„å·®è·æœ‰å¤šé ã€‚\n",
    "\n",
    "\n",
    "1.   iou -->è¨ˆç®—å…©å€‹bboxçš„iouå€¼\n",
    "2.   body1-->æ¨™è¨˜æ¡†åšè½‰æ›ï¼Œç„¶å¾Œå’Œé æ¸¬æ¡†è¨ˆç®—ç”¢ç”Ÿæå¤±å‡½æ•¸\n",
    "3.   loss -->è¨ˆç®—æ¯ä¸€å€‹æ¨™è¨˜æ¡†å’Œæ‰€æœ‰é æ¸¬æ¡†çš„æå¤±\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ub7qJfrbFVI"
   },
   "source": [
    "### loss function å‡½æ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZhCbltPbFVJ"
   },
   "outputs": [],
   "source": [
    "# åƒæ•¸çš„è¨­å®š\n",
    "image_size=448\n",
    "num_classes=20\n",
    "batch_size=1\n",
    "\n",
    "cell_size=7\n",
    "boxes_per_cell=2\n",
    "weight_decay=0.0005\n",
    "class_scale=2.0\n",
    "object_scale=1.0\n",
    "noobject_scale= 0.5\n",
    "coord_scale=5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQKu4XDtbFVN"
   },
   "outputs": [],
   "source": [
    "def iou(boxes1, boxes2):\n",
    "    \"\"\"calculate ious\n",
    "    selfä»£è¡¨æŸå‘¼å«é€™å€‹å‡½æ•¸çš„ç‰©ä»¶æœ¬èº«\n",
    "    Args:\n",
    "      boxes1:(ä»£è¡¨é æ¸¬æ¡†) 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  \n",
    "      4åˆ†åˆ¥ä»£è¡¨====> (x_center, y_center, w, h)\n",
    "      boxes2:(ä»£è¡¨å¯¦éš›æ¡†) 1-D tensor [4] ===> (x_center, y_center, w, h)\n",
    "    Return:\n",
    "      å›å‚³iouçš„å€¼\n",
    "      iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "      \n",
    "    \"\"\"\n",
    "    # (x_center-w/2),(y_center-h/2),(x_center+w/2),(y_center+h/2)=(å·¦ä¸Šæ–¹åº§æ¨™ï¼Œå³ä¸‹æ–¹åº§æ¨™)\n",
    "    boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n",
    "                      boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\n",
    "    boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\n",
    "    boxes2 =  tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n",
    "                      boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n",
    "\n",
    "    #calculate the left up point\n",
    "    #è¨ˆç®—äº¤é›†çš„å·¦ä¸Šæ–¹é»ï¼Œå’Œå³ä¸‹æ–¹é»\n",
    "    lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\n",
    "    rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n",
    "\n",
    "    #intersection\n",
    "    #äº¤é›†(intersection)\n",
    "    intersection = rd - lu \n",
    "    #äº¤é›†é¢ç©\n",
    "    inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n",
    "    #åªå–é•·å¯¬>0çš„æ‰åšè¨ˆç®—\n",
    "    mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n",
    "    \n",
    "    inter_square = mask * inter_square\n",
    "    \n",
    "    #calculate the boxs1 square and boxs2 square\n",
    "    #è¨ˆç®—è¯é›†é¢ç©ï¼Œç­‰æ–¼å…©å€‹æ–¹å½¢å€å¡Š-äº¤é›†é¢ç©(calculate the boxs1 square and boxs2 square)\n",
    "    square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\n",
    "    square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "    return inter_square/(square1 + square2 - inter_square + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U862awLqbFVT"
   },
   "outputs": [],
   "source": [
    "def cond1(num, object_num, loss, predict, label, nilboy):\n",
    "    \"\"\"\n",
    "    if num < object_num\n",
    "    \"\"\"\n",
    "    return num < object_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XQ0icyLbFVb"
   },
   "outputs": [],
   "source": [
    "def body1(num, object_num, loss, predict, labels, nilboy):\n",
    "    \"\"\"\n",
    "    calculate loss\n",
    "    Args:\n",
    "      predict(é æ¸¬æ¡†çµæœ): 3-D tensor [cell_size, cell_size, 5 * boxes_per_cell]\n",
    "      labels(æ¨™è¨˜æ¡†) : [max_objects, 5]  (x_center, y_center, w, h, class)\n",
    "      #max_objects,ç´€éŒ„ç‰©é«”çš„ç¸½æ•¸é‡\n",
    "    \"\"\"\n",
    "    # ç”¨ num æ§åˆ¶ç¾åœ¨æ˜¯è¨ˆç®—ç¬¬å¹¾å€‹ç‰©ä»¶çš„æ¨™è¨˜æ¡†ï¼Œå–å‡ºä¾†è¨ˆç®—\n",
    "\n",
    "    label = labels[num:num+1, :]\n",
    "    label = tf.reshape(label, [-1])\n",
    "\n",
    "    #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n",
    "    #åˆ¤æ–·æ˜¯å¦æœ‰æŸä¸€ç‰©é«”æ¨™è¨˜æ¡†ä¸­å¿ƒè½åœ¨ç¶²æ ¼i ä¸­ ==>1^{object}_{i}\n",
    "    #objects\n",
    "    min_x = (label[0] - label[2] / 2) / (image_size / cell_size)\n",
    "    max_x = (label[0] + label[2] / 2) / (image_size / cell_size)\n",
    "\n",
    "    min_y = (label[1] - label[3] / 2) / (image_size / cell_size)\n",
    "    max_y = (label[1] + label[3] / 2) / (image_size / cell_size)\n",
    "    #è¨ˆç®—ä¸å¤§æ–¼ min_xçš„æœ€å¤§æ•´æ•¸\n",
    "    min_x = tf.floor(min_x)\n",
    "    min_y = tf.floor(min_y)\n",
    "    #è¨ˆç®—ä¸å°æ–¼ min_xçš„æœ€å°æ•´æ•¸\n",
    "    max_x = tf.ceil(max_x)\n",
    "    max_y = tf.ceil(max_y)\n",
    "\n",
    "    #ç›¸æ¸›ï¼Œè¨ˆç®—ç‰©é«”æ¶µè“‹çš„cellç¯„åœ\n",
    "    temp = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\n",
    "    objects = tf.ones(temp, tf.float32)\n",
    "\n",
    "    temp = tf.cast(tf.stack([min_y, cell_size - max_y, min_x, cell_size - max_x]), tf.int32)\n",
    "    temp = tf.reshape(temp, (2, 2))\n",
    "    objects = tf.pad(objects, temp, \"CONSTANT\")\n",
    "\n",
    "    #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n",
    "    #calculate responsible tensor [CELL_SIZE, CELL_SIZE]-->1^{object}_{ij}\n",
    "    #åˆ¤æ–·ç¬¬ I å€‹ç¶²æ ¼ä¸­ç¬¬ j å€‹bboxæ˜¯å¦è² è²¬é€™å€‹ç‰©é«”\n",
    "    center_x = label[0] / (image_size / cell_size)\n",
    "    center_x = tf.floor(center_x)\n",
    "\n",
    "    center_y = label[1] / (image_size / cell_size)\n",
    "    center_y = tf.floor(center_y)\n",
    "\n",
    "    response = tf.ones([1, 1], tf.float32)\n",
    "\n",
    "    temp = tf.cast(tf.stack([center_y, cell_size - center_y - 1, center_x, cell_size -center_x - 1]), tf.int32)\n",
    "    temp = tf.reshape(temp, (2, 2))\n",
    "    response = tf.pad(response, temp, \"CONSTANT\")\n",
    "    #objects = response\n",
    "\n",
    "    #calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    #å–å‡º box\n",
    "    predict_boxes = predict[:, :, num_classes + boxes_per_cell:]\n",
    "    \n",
    "    #é‡æ–° reshape\n",
    "    predict_boxes = tf.reshape(predict_boxes, [cell_size, cell_size, boxes_per_cell, 4])\n",
    "\n",
    "    predict_boxes = predict_boxes * [image_size / cell_size, image_size / cell_size, image_size, image_size]\n",
    "\n",
    "    base_boxes = np.zeros([cell_size, cell_size, 4])\n",
    "\n",
    "    for y in range(cell_size):\n",
    "      for x in range(cell_size):\n",
    "        #nilboy\n",
    "        base_boxes[y, x, :] = [image_size / cell_size * x, image_size / cell_size * y, 0, 0]\n",
    "    base_boxes = np.tile(np.resize(base_boxes, [cell_size, cell_size, 1, 4]), [1, 1, boxes_per_cell, 1])\n",
    "\n",
    "    predict_boxes = base_boxes + predict_boxes\n",
    "\n",
    "    iou_predict_truth = iou(predict_boxes, label[0:4])\n",
    "    #calculate C [cell_size, cell_size, boxes_per_cell]\n",
    "    C = iou_predict_truth * tf.reshape(response, [cell_size, cell_size, 1])\n",
    "\n",
    "    #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    #åˆ¤æ–·ç¬¬ I å€‹ç¶²æ ¼ä¸­ç¬¬ j å€‹bboxæ˜¯å¦è² è²¬é€™å€‹ç‰©é«”\n",
    "    I = iou_predict_truth * tf.reshape(response, (cell_size, cell_size, 1))\n",
    "    \n",
    "    max_I = tf.reduce_max(I, 2, keepdims=True)\n",
    "\n",
    "    I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (cell_size, cell_size, 1))\n",
    "\n",
    "    #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    no_I = tf.ones_like(I, dtype=tf.float32) - I \n",
    "\n",
    "\n",
    "    p_C = predict[:, :, num_classes:num_classes + boxes_per_cell]\n",
    "\n",
    "    #calculate truth x,y,sqrt_w,sqrt_h 0-D\n",
    "    x = label[0]\n",
    "    y = label[1]\n",
    "\n",
    "    sqrt_w = tf.sqrt(tf.abs(label[2]))\n",
    "    sqrt_h = tf.sqrt(tf.abs(label[3]))\n",
    "    #sqrt_w = tf.abs(label[2])\n",
    "    #sqrt_h = tf.abs(label[3])\n",
    "\n",
    "    #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    p_x = predict_boxes[:, :, :, 0]\n",
    "    p_y = predict_boxes[:, :, :, 1]\n",
    "\n",
    "\n",
    "    p_sqrt_w = tf.sqrt(tf.minimum(image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\n",
    "    p_sqrt_h = tf.sqrt(tf.minimum(image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n",
    "    #calculate truth p 1-D tensor [NUM_CLASSES]\n",
    "    P = tf.one_hot(tf.cast(label[4], tf.int32), num_classes, dtype=tf.float32)\n",
    "\n",
    "    #calculate predict p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\n",
    "    p_P = predict[:, :, 0:num_classes]\n",
    "\n",
    "    #class_loss\n",
    "    class_loss = tf.nn.l2_loss(tf.reshape(objects, (cell_size, cell_size, 1)) * (p_P - P)) * class_scale\n",
    "    #class_loss = tf.nn.l2_loss(tf.reshape(response, (cell_size, cell_size, 1)) * (p_P - P)) * class_scale\n",
    "\n",
    "    #object_loss\n",
    "    object_loss = tf.nn.l2_loss(I * (p_C - C)) * object_scale\n",
    "\n",
    "    #noobject_loss\n",
    "    noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * noobject_scale\n",
    "\n",
    "    #coord_loss\n",
    "    coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(image_size/cell_size)) +\n",
    "                 tf.nn.l2_loss(I * (p_y - y)/(image_size/cell_size)) +\n",
    "                 tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/ image_size +\n",
    "                 tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/image_size) * coord_scale\n",
    "\n",
    "    nilboy = I\n",
    "\n",
    "    with tf.Session() as sess1:\n",
    "        print(\"ç¬¬å¹¾å€‹æ¨™è¨˜æ¡†\",sess1.run(num))\n",
    "        #print(sess1.run(num)) \n",
    "        print(sess1.run(label)) \n",
    "        print(\"class_loss =\",sess1.run(class_loss))\n",
    "        print(\"object_loss=\",sess1.run(object_loss))\n",
    "        print(\"noobject_loss=\",sess1.run(noobject_loss))\n",
    "        print(\"coord_loss=\",sess1.run(coord_loss))\n",
    "    return num + 1, object_num, [loss[0] + class_loss, loss[1] + object_loss, loss[2] + noobject_loss, loss[3] + coord_loss], predict, labels, nilboy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgHRoc3rbFVf"
   },
   "outputs": [],
   "source": [
    "def loss(predicts, labels, objects_num):\n",
    "    \"\"\"Add Loss to all the trainable variables\n",
    "\n",
    "    Args:\n",
    "      predicts: 4-D tensor [batch_size, cell_size, cell_size, 5 * boxes_per_cell]\n",
    "      ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\n",
    "      labels  : 3-D tensor of [batch_size, max_objects, 5]\n",
    "      objects_num: 1-D tensor [batch_size]\n",
    "    \"\"\"\n",
    "    print(\"loss\")\n",
    "    class_loss = tf.constant(0, tf.float32) #bboxç‰©ä»¶é¡åˆ¥è¨ˆç®—æå¤±\n",
    "    object_loss = tf.constant(0, tf.float32) #bbox ç‰©ä»¶ä¿¡å¿ƒåº¦è¨ˆç®—æå¤±\n",
    "    noobject_loss = tf.constant(0, tf.float32) #bbox ç„¡ç‰©ä»¶ä¿¡å¿ƒåº¦è¨ˆç®—æå¤±\n",
    "    coord_loss = tf.constant(0, tf.float32) #bboxçš„å®šä½è¨ˆç®—æå¤±\n",
    "    loss = [0, 0, 0, 0]\n",
    "    #æ¯ä¸€å¼µåœ–éƒ½å„è‡ªè¨ˆç®— loss\n",
    "    for i in range(batch_size):\n",
    "      predict = predicts[i, :, :, :]\n",
    "      #print(\"predict==\",predicts.shape.as_list())\n",
    "      label = labels[i, :, :]\n",
    "      object_num = objects_num[i]\n",
    "      nilboy = tf.ones([7,7,2])\n",
    "      #ä»¥æ¯ä¸€å€‹æ¨™è¨˜æ¡†åˆ†åˆ¥è¨ˆç®—æ¯ä¸€å¼µåœ–æ˜¯å¦æœ‰é‚£ä¸€å€‹ç‰©ä»¶ï¼Œé€²è¡Œæå¤±å‡½æ•¸çš„é‹ç®—\n",
    "      tuple_results = body1(tf.constant(0), object_num, [class_loss, object_loss, noobject_loss, coord_loss], predict, label, nilboy)\n",
    "      for j in range(4):\n",
    "        loss[j] = loss[j] + tuple_results[2][j]\n",
    "      tuple_results = body1(tf.constant(1), object_num, [class_loss, object_loss, noobject_loss, coord_loss], predict, label, nilboy)\n",
    "  \n",
    "      for j in range(4):\n",
    "        loss[j] = loss[j] + tuple_results[2][j]\n",
    "      tuple_results = body1(tf.constant(2), object_num, [class_loss, object_loss, noobject_loss, coord_loss], predict, label, nilboy)\n",
    "     \n",
    "      for j in range(4):\n",
    "        loss[j] = loss[j] + tuple_results[2][j]\n",
    "      nilboy = tuple_results[5]\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ARNv7PLmbFVl"
   },
   "source": [
    "### è¨ˆç®—æ¨™è¨˜æ¡†å’Œé æ¸¬æ¡†çš„loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11627,
     "status": "ok",
     "timestamp": 1578970928124,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "cAUyFiKmbFVn",
    "outputId": "416f5fc1-5522-4002-8ec5-67d301dadb60"
   },
   "outputs": [],
   "source": [
    "predicts=tf.reshape(np_predict,(1, 7, 7, 30))\n",
    "labels=tf.reshape(labels, (1,3, 5))\n",
    "#output_loss=net.loss(predicts, labels,  tf.constant(3, shape=[1]))\n",
    "output_loss=loss(predicts, labels,  tf.constant(3, shape=[1]))\n",
    "print(\"é æ¸¬çµæœå’Œæ¨™è¨˜æ¡†çš„æå¤±é‡\")\n",
    "with tf.Session() as sess1: \n",
    "    print(sess1.run(output_loss)) \n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JG0RjWTRaK80"
   },
   "source": [
    "##  é€™å€‹ç¯„ä¾‹ç¨‹å¼ç¢¼ä¸­çš„å‡½æ•¸,ç‚ºäº†è¦å‘ˆç¾æå¤±å‡½æ•¸çš„çµæœæœ‰äº›å¾®èª¿ï¼Œæœ‰èˆˆè¶£æƒ³æ›´æ·±å…¥äº†è§£çš„åŒå­¸ï¼Œå¯ä»¥é€éSublime Textè»Ÿé«”ï¼Œé–‹å•Ÿè³‡æ–™å¤¾\\yolo\\net\\yolo\\yolo_net.pyçš„ç¨‹å¼ç¢¼ã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day35_yolo_loss.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
