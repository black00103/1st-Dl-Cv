{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "piG8kRMgbFTz"
   },
   "source": [
    "## 範例\n",
    "YOLO 的網路輸出是一個 7x7x30 的 tensor,\n",
    "\n",
    "而今天的程式碼範例的目標是讓大家由程式碼實現損失函數的計算，透過損失函數衡量一張圖片經由 YOLO 模型辨識後的結果和標記檔的差距有多遠。\n",
    "今天的範例，採用的是YOLOv1_tiny的網絡。\n",
    "\n",
    "資料來源: https://github.com/solaris33/dl_cv_tensorflow_10weeks/blob/master/week10/tensorflow-yolo/yolo/net/yolo_net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5agKBc5MbFT2"
   },
   "source": [
    "輸入所需的library，這邊會呼叫到其他的程式碼(YoloTinyNet.py)，\n",
    "預測的類型(classes_name)共有20種。\n",
    "\n",
    "首先，我們先開一個\"Day35.YOLO 細節理解 - 損失函數程式碼解讀\"的google雲端空間資料夾，\n",
    "把系統的程式碼上傳到這個資料夾中。\n",
    "下面程式碼，我們先把google的雲端硬碟連結到colab上，在使用python將工作路徑切換到你想要的文件夾，就可以在colab上運行python並抓取到相對的檔案。\n",
    "\n",
    "首先執行程式後，下方會跳出一個超連結，\n",
    "1.   點選你的google帳號\n",
    "2.   點選允許colab能操作你的雲端硬碟，\n",
    "3.   跳出另一個畫面，點右邊的小方格，複製連結，\n",
    "4.   貼到Enter your authorization code:下方的小框框，按下enter。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7yCo2N5b3D5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom google.colab import drive\\ndrive.mount(\\'/content/drive\\')\\n# 指定google drive雲端硬碟的跟目錄，名為drive\\n#!mkdir -p drive\\n#!google-drive-ocamlfuse drive\\n\\nimport os\\n# 此處為google drive中的文件路徑，drive為之前指定的工作跟目錄，要加上位置\\n# 如果存放的路徑有變，從/content/drive/My Drive/XXXXX...做調整\\npath = \"Day35\"\\nos.chdir(path)\\n\\n!ls\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# 指定google drive雲端硬碟的跟目錄，名為drive\n",
    "#!mkdir -p drive\n",
    "#!google-drive-ocamlfuse drive\n",
    "\n",
    "import os\n",
    "# 此處為google drive中的文件路徑，drive為之前指定的工作跟目錄，要加上位置\n",
    "# 如果存放的路徑有變，從/content/drive/My Drive/XXXXX...做調整\n",
    "path = \"Day35\"\n",
    "os.chdir(path)\n",
    "!ls\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5319,
     "status": "ok",
     "timestamp": 1578970921448,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "pvdtB3HE7gJx",
    "outputId": "f4fd899e-1fa5-4cd5-c14f-555a4e2ce3a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' 不是內部或外部命令、可執行的程式或批次檔。\n"
     ]
    }
   ],
   "source": [
    "#!ls yolo/net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5303,
     "status": "ok",
     "timestamp": 1578970921451,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "xE6PP2af46a_",
    "outputId": "439a87ab-f44f-4e09-e3b9-81aee95c0464"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yolo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c8c909aa30f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yolo/net'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#Now we can import the library and use the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0myolo_tiny_net\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mYoloTinyNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m#%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\D35\\yolo_tiny_net.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mYoloTinyNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yolo'"
     ]
    }
   ],
   "source": [
    "#We'll need to update our path to import from Drive.\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = \"Day35\"\n",
    "#sys.path.append(os.path.join(path, \"yolo/net\"))\n",
    "#os.chdir(path)\n",
    "sys.path.append('yolo/net')\n",
    "#Now we can import the library and use the function.\n",
    "from yolo_tiny_net import YoloTinyNet \n",
    "#%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5292,
     "status": "ok",
     "timestamp": 1578970921452,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "aW4kXKVJJPOZ",
    "outputId": "b67c9ba7-5192-41b7-89c1-57e63eadbb2b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "if not os.path.exists(\"Day35.YOLO 細節理解 - 損失函數/models/pretrain/yolo_tiny.ckpt\"):\n",
    "  # 下載 yolo_tiny 的網路權重\n",
    "  print(\"Model doesn't exist, downloading...\")\n",
    "  os.system(\"wget https://drive.google.com/file/d/0B-yiAeTLLamRekxqVE01Yi1RRlk/view?usp=sharing\")\n",
    "#  print(\"Converting yolov3.weights to yolo.h5...\")\n",
    "#  os.system(\"python convert.py yolov3.cfg yolov3.weights models/pretrain/yolo_tiny.ckpt\")\n",
    "else:\n",
    "  print(\"Model exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Z5rqCiCbFT4"
   },
   "outputs": [],
   "source": [
    "#from yolo.net.yolo_tiny_net import YoloTinyNet \n",
    "#from yolo import YOLO # 從 yolo.py 中將該項目定義的 YOLO class 載入，其詳細定義請參考 yolo.py\n",
    "import tensorflow as tf \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "tf.reset_default_graph() #避免Python的控制檯會儲存上次執行結束的變數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APeoGwejbFT_"
   },
   "source": [
    "讀入資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8440,
     "status": "ok",
     "timestamp": 1578970924621,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "-quWCGQlbFUA",
    "outputId": "16256fc1-f4b2-4fbb-e065-0d65e285baf1"
   },
   "outputs": [],
   "source": [
    "# 下載圖片範例，如果已經下載過就可以註解掉\n",
    "#!wget https://github.com/pjreddie/darknet/blob/master/data/dog.jpg?raw=true -O dog.jpg\n",
    "img = cv2.imread(\"dog.jpg\") # 讀取範例圖片\n",
    "h, w, _ = img.shape\n",
    "print(img.shape)\n",
    "def show(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # plt.imshow 預設圖片是 rgb 的\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8430,
     "status": "ok",
     "timestamp": 1578970924622,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "VQ_hvwU3bFUE",
    "outputId": "7dd97453-44d4-4fcc-d4ae-751e8b973284"
   },
   "outputs": [],
   "source": [
    "boxes = np.array([[128, 224, 314, 537], [475, 85, 689, 170], [162, 119, 565, 441]]).astype(float)\n",
    "# 把 bboxes 坐標以原圖的 resolution normalize 到 0~1 之間\n",
    "boxes[:, [0, 2]] = boxes[:, [0, 2]] / img.shape[1]\n",
    "boxes[:, [1, 3]] = boxes[:, [1, 3]] / img.shape[0]\n",
    "\n",
    "img_show = img.copy()\n",
    "for x1, y1, x2, y2 in boxes:\n",
    "    cv2.rectangle(img_show, (int(x1*w), int(y1*h)), (int(x2*w), int(y2*h)), (0, 255, 0), 2)\n",
    "show(img_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9280,
     "status": "ok",
     "timestamp": 1578970925487,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "IdeZ69vachDL",
    "outputId": "e543a709-7e54-4415-f320-1a255eec3d43"
   },
   "outputs": [],
   "source": [
    "#模擬影像的標記檔結果\n",
    "# yolo輸入的是448*448，所以原始大小要先縮成448*448，所以原本的標記框大小也要對應轉換\n",
    "dy=448/576\n",
    "dx=448/768\n",
    "boxes = np.array([[128*dx, 224*dy, 314*dx, 537*dy], [475*dx, 85*dy, 689*dx, 170*dy], [162*dx, 119*dy, 565*dx, 441*dy]]).astype(float)\n",
    "np_img = cv2.imread('dog.jpg')\n",
    "resized_img = cv2.resize(np_img, (448, 448))\n",
    "img_show = resized_img.copy()\n",
    "for x1, y1, x2, y2 in boxes:\n",
    "    cv2.rectangle(img_show, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "show(img_show)\n",
    "print(boxes[0,])\n",
    "print(boxes[1,])\n",
    "print(boxes[2,])\n",
    "#可以檢視一下，轉換後標記的結果的確能框住物體"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9267,
     "status": "ok",
     "timestamp": 1578970925489,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "qwkNKZiwfF0Q",
    "outputId": "a88ca3a9-183c-421a-876f-472bc19d1d56"
   },
   "outputs": [],
   "source": [
    "#標記檔: labels轉成 loss 函數所需的格式,(xmin,ymin,xmax,ymax)-->(x_center, y_center, w, h,class) in (448,448)\n",
    "labels = np.zeros((3, 5)) \n",
    "#labels [0,0:4]=boxes[0,]\n",
    "#labels [1,0:4]=boxes[1,]\n",
    "#labels [2,0:4]=boxes[2,]\n",
    "\n",
    "#print(labels)\n",
    "labels [:,0]=(boxes[:,0]+boxes[:,2])/2\n",
    "labels [:,1]=(boxes[:,1]+boxes[:,3])/2\n",
    "\n",
    "labels [:,2]=boxes[:,2]-boxes[:,0]\n",
    "labels [:,3]=boxes[:,3]-boxes[:,1]\n",
    "\n",
    "\n",
    "labels [0,4]=6\n",
    "labels [1,4]=1\n",
    "labels [2,4]=11\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9233,
     "status": "ok",
     "timestamp": 1578970925490,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "l13_M-_PftRK",
    "outputId": "4e38e784-c724-4d42-88ed-60a89d2a16d1"
   },
   "outputs": [],
   "source": [
    "print(labels)\n",
    "labels = tf.reshape(labels, (3, 5))\n",
    "labels = tf.cast(labels, tf.float32) \n",
    "#為了後續運算轉成 float32\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VI3E-EEibFUH"
   },
   "outputs": [],
   "source": [
    "#輸出層解碼\n",
    "def process_predicts(predicts):\n",
    "  #類別\n",
    "  p_classes = predicts[0, :, :, 0:20]\n",
    "  #個別bbox包含有物件的機率\n",
    "  C = predicts[0, :, :, 20:22]\n",
    "  #個別bbox的標記框位置\n",
    "  coordinate = predicts[0, :, :, 22:]\n",
    "\n",
    "  p_classes = np.reshape(p_classes, (7, 7, 1, 20))\n",
    "  C = np.reshape(C, (7, 7, 2, 1))\n",
    "\n",
    "  #對應相乘，產生𝑝(〖𝐶𝑙𝑎𝑠𝑠〗_𝑗 |𝑜𝑏𝑗𝑒𝑐𝑡)*𝑃(𝑜𝑏𝑗𝑒𝑐𝑡)\n",
    "  P = C * p_classes\n",
    "\n",
    "  index = np.argmax(P) #返還最大值索引(486)\n",
    "  #print(index) #486\n",
    "  index = np.unravel_index(index, P.shape)#(7, 7, 1, 20)\n",
    "  #print(index) #(1, 5, 0, 6)\n",
    "\n",
    "  class_num = index[3]\n",
    "\n",
    "  coordinate = np.reshape(coordinate, (7, 7, 2, 4))\n",
    "\n",
    "  max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "  xcenter = max_coordinate[0]\n",
    "  #print(\"xcenter=\",xcenter)\n",
    "  ycenter = max_coordinate[1]\n",
    "  #print(\"ycenter=\",ycenter)\n",
    "  w = max_coordinate[2]\n",
    "  #print(\"w=\",w)\n",
    "  h = max_coordinate[3]\n",
    "  #print(\"h=\",h)\n",
    "  \n",
    "  #index[1] : x 網格位置\n",
    "  xcenter = (index[1] + xcenter) * (448/7.0)\n",
    "  # index[0]: y網格位置\n",
    "  ycenter = (index[0] + ycenter) * (448/7.0)\n",
    "\n",
    "  w = w * 448\n",
    "  h = h * 448\n",
    "\n",
    "  xmin = xcenter - w/2.0\n",
    "  ymin = ycenter - h/2.0\n",
    "\n",
    "  xmax = xmin + w\n",
    "  ymax = ymin + h\n",
    "\n",
    "  return xmin, ymin, xmax, ymax, class_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIZxrGwUbFUM"
   },
   "source": [
    "### 設定YoloTinyNet \n",
    "透過YoloTinyNet產生一個預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9xIMzgFbFUN"
   },
   "outputs": [],
   "source": [
    "common_params = {'image_size': 448, 'num_classes': 20, \n",
    "                'batch_size':1}\n",
    "net_params = {'cell_size': 7, 'boxes_per_cell':2, 'weight_decay': 0.0005, 'class_scale': 2.0,\n",
    "'object_scale':1.0, 'noobject_scale': 0.5, 'coord_scale': 5.0}\n",
    "\n",
    "net = YoloTinyNet(common_params, net_params, test=False)\n",
    "#net = YoloNet(common_params, net_params, test=True)\n",
    "\n",
    "# Tensorflow 如果想要從外部傳入data,那就要用到 tf.placeholder()，然後以這種形式傳輸數據， sess.run(***,feed_dict={input: **})\n",
    "# 傳值的工作交給 sess.run(),需要傳入的值放在 feed_dict={}，一一對應每一個 input, placeholder和 feed_dict={}是綁定在一出現的。 \n",
    "image = tf.placeholder(tf.float32, (1, 448, 448, 3))\n",
    "predicts = net.inference(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9587,
     "status": "ok",
     "timestamp": 1578970925927,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "p2RUlgT0bFUS",
    "outputId": "21fa98d9-36da-4540-c2dd-984403c8aebc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Session 是 Tensorflow 開啟一個對話，執行輸出結果。\n",
    "sess = tf.Session()\n",
    "np_img = cv2.imread('dog.jpg')\n",
    "resized_img = cv2.resize(np_img, (448, 448))\n",
    "np_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "np_img = np_img.astype(np.float32)\n",
    "\n",
    "np_img = np_img / 255.0 * 2 - 1\n",
    "np_img = np.reshape(np_img, (1, 448, 448, 3))\n",
    "\n",
    "#一些設定的函數，先跳過。\n",
    "saver = tf.train.Saver(net.trainable_collection)\n",
    "#輸入網絡架構的參數檔\n",
    "saver.restore(sess, 'models/pretrain/yolo_tiny.ckpt')\n",
    "#開啟對話，進行預測\n",
    "np_predict = sess.run(predicts, feed_dict={image: np_img})\n",
    "print(np_predict.shape)\n",
    "print(np_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BYiq-kKEbFUX"
   },
   "source": [
    "### 預測出來產生的結果檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9564,
     "status": "ok",
     "timestamp": 1578970925928,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "gGzfeXuobFUY",
    "outputId": "4c6d949d-31ea-4659-9297-1ebde6fe5ba6"
   },
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax, class_num = process_predicts(np_predict)\n",
    "print(\"output\")\n",
    "print(xmin)\n",
    "print(ymin)\n",
    "print(xmax)\n",
    "print(ymax)\n",
    "print(class_num) #\"car\"\n",
    "class_name = classes_name[class_num]\n",
    "print(class_name)\n",
    "#畫出對應框\n",
    "cv2.rectangle(resized_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 0, 255))\n",
    "cv2.putText(resized_img, class_name, (int(xmin), int(ymin)), 2, 1.5, (0, 0, 255))\n",
    "#結果輸出\n",
    "cv2.imwrite('dog_out.jpg', resized_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wUS-ZPoNbVmj"
   },
   "source": [
    "可以看一下雲端硬碟的空間裡有沒有多一張dog_out.jpg，\n",
    "接下來我們透過三個函數，計算一張圖片經由 YOLO 模型辨識後的結果和標記檔的差距有多遠。\n",
    "\n",
    "\n",
    "1.   iou -->計算兩個bbox的iou值\n",
    "2.   body1-->標記框做轉換，然後和預測框計算產生損失函數\n",
    "3.   loss -->計算每一個標記框和所有預測框的損失\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ub7qJfrbFVI"
   },
   "source": [
    "### loss function 函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZhCbltPbFVJ"
   },
   "outputs": [],
   "source": [
    "# 參數的設定\n",
    "image_size=448\n",
    "num_classes=20\n",
    "batch_size=1\n",
    "\n",
    "cell_size=7\n",
    "boxes_per_cell=2\n",
    "weight_decay=0.0005\n",
    "class_scale=2.0\n",
    "object_scale=1.0\n",
    "noobject_scale= 0.5\n",
    "coord_scale=5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQKu4XDtbFVN"
   },
   "outputs": [],
   "source": [
    "def iou(boxes1, boxes2):\n",
    "    \"\"\"calculate ious\n",
    "    self代表某呼叫這個函數的物件本身\n",
    "    Args:\n",
    "      boxes1:(代表預測框) 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  \n",
    "      4分別代表====> (x_center, y_center, w, h)\n",
    "      boxes2:(代表實際框) 1-D tensor [4] ===> (x_center, y_center, w, h)\n",
    "    Return:\n",
    "      回傳iou的值\n",
    "      iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "      \n",
    "    \"\"\"\n",
    "    # (x_center-w/2),(y_center-h/2),(x_center+w/2),(y_center+h/2)=(左上方座標，右下方座標)\n",
    "    boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n",
    "                      boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\n",
    "    boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\n",
    "    boxes2 =  tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n",
    "                      boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n",
    "\n",
    "    #calculate the left up point\n",
    "    #計算交集的左上方點，和右下方點\n",
    "    lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\n",
    "    rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n",
    "\n",
    "    #intersection\n",
    "    #交集(intersection)\n",
    "    intersection = rd - lu \n",
    "    #交集面積\n",
    "    inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n",
    "    #只取長寬>0的才做計算\n",
    "    mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n",
    "    \n",
    "    inter_square = mask * inter_square\n",
    "    \n",
    "    #calculate the boxs1 square and boxs2 square\n",
    "    #計算聯集面積，等於兩個方形區塊-交集面積(calculate the boxs1 square and boxs2 square)\n",
    "    square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\n",
    "    square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "    return inter_square/(square1 + square2 - inter_square + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U862awLqbFVT"
   },
   "outputs": [],
   "source": [
    "def cond1(num, object_num, loss, predict, label, nilboy):\n",
    "    \"\"\"\n",
    "    if num < object_num\n",
    "    \"\"\"\n",
    "    return num < object_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XQ0icyLbFVb"
   },
   "outputs": [],
   "source": [
    "def body1(num, object_num, loss, predict, labels, nilboy):\n",
    "    \"\"\"\n",
    "    calculate loss\n",
    "    Args:\n",
    "      predict(預測框結果): 3-D tensor [cell_size, cell_size, 5 * boxes_per_cell]\n",
    "      labels(標記框) : [max_objects, 5]  (x_center, y_center, w, h, class)\n",
    "      #max_objects,紀錄物體的總數量\n",
    "    \"\"\"\n",
    "    # 用 num 控制現在是計算第幾個物件的標記框，取出來計算\n",
    "\n",
    "    label = labels[num:num+1, :]\n",
    "    label = tf.reshape(label, [-1])\n",
    "\n",
    "    #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n",
    "    #判斷是否有某一物體標記框中心落在網格i 中 ==>1^{object}_{i}\n",
    "    #objects\n",
    "    min_x = (label[0] - label[2] / 2) / (image_size / cell_size)\n",
    "    max_x = (label[0] + label[2] / 2) / (image_size / cell_size)\n",
    "\n",
    "    min_y = (label[1] - label[3] / 2) / (image_size / cell_size)\n",
    "    max_y = (label[1] + label[3] / 2) / (image_size / cell_size)\n",
    "    #計算不大於 min_x的最大整數\n",
    "    min_x = tf.floor(min_x)\n",
    "    min_y = tf.floor(min_y)\n",
    "    #計算不小於 min_x的最小整數\n",
    "    max_x = tf.ceil(max_x)\n",
    "    max_y = tf.ceil(max_y)\n",
    "\n",
    "    #相減，計算物體涵蓋的cell範圍\n",
    "    temp = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\n",
    "    objects = tf.ones(temp, tf.float32)\n",
    "\n",
    "    temp = tf.cast(tf.stack([min_y, cell_size - max_y, min_x, cell_size - max_x]), tf.int32)\n",
    "    temp = tf.reshape(temp, (2, 2))\n",
    "    objects = tf.pad(objects, temp, \"CONSTANT\")\n",
    "\n",
    "    #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n",
    "    #calculate responsible tensor [CELL_SIZE, CELL_SIZE]-->1^{object}_{ij}\n",
    "    #判斷第 I 個網格中第 j 個bbox是否負責這個物體\n",
    "    center_x = label[0] / (image_size / cell_size)\n",
    "    center_x = tf.floor(center_x)\n",
    "\n",
    "    center_y = label[1] / (image_size / cell_size)\n",
    "    center_y = tf.floor(center_y)\n",
    "\n",
    "    response = tf.ones([1, 1], tf.float32)\n",
    "\n",
    "    temp = tf.cast(tf.stack([center_y, cell_size - center_y - 1, center_x, cell_size -center_x - 1]), tf.int32)\n",
    "    temp = tf.reshape(temp, (2, 2))\n",
    "    response = tf.pad(response, temp, \"CONSTANT\")\n",
    "    #objects = response\n",
    "\n",
    "    #calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    #取出 box\n",
    "    predict_boxes = predict[:, :, num_classes + boxes_per_cell:]\n",
    "    \n",
    "    #重新 reshape\n",
    "    predict_boxes = tf.reshape(predict_boxes, [cell_size, cell_size, boxes_per_cell, 4])\n",
    "\n",
    "    predict_boxes = predict_boxes * [image_size / cell_size, image_size / cell_size, image_size, image_size]\n",
    "\n",
    "    base_boxes = np.zeros([cell_size, cell_size, 4])\n",
    "\n",
    "    for y in range(cell_size):\n",
    "      for x in range(cell_size):\n",
    "        #nilboy\n",
    "        base_boxes[y, x, :] = [image_size / cell_size * x, image_size / cell_size * y, 0, 0]\n",
    "    base_boxes = np.tile(np.resize(base_boxes, [cell_size, cell_size, 1, 4]), [1, 1, boxes_per_cell, 1])\n",
    "\n",
    "    predict_boxes = base_boxes + predict_boxes\n",
    "\n",
    "    iou_predict_truth = iou(predict_boxes, label[0:4])\n",
    "    #calculate C [cell_size, cell_size, boxes_per_cell]\n",
    "    C = iou_predict_truth * tf.reshape(response, [cell_size, cell_size, 1])\n",
    "\n",
    "    #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    #判斷第 I 個網格中第 j 個bbox是否負責這個物體\n",
    "    I = iou_predict_truth * tf.reshape(response, (cell_size, cell_size, 1))\n",
    "    \n",
    "    max_I = tf.reduce_max(I, 2, keepdims=True)\n",
    "\n",
    "    I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (cell_size, cell_size, 1))\n",
    "\n",
    "    #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    no_I = tf.ones_like(I, dtype=tf.float32) - I \n",
    "\n",
    "\n",
    "    p_C = predict[:, :, num_classes:num_classes + boxes_per_cell]\n",
    "\n",
    "    #calculate truth x,y,sqrt_w,sqrt_h 0-D\n",
    "    x = label[0]\n",
    "    y = label[1]\n",
    "\n",
    "    sqrt_w = tf.sqrt(tf.abs(label[2]))\n",
    "    sqrt_h = tf.sqrt(tf.abs(label[3]))\n",
    "    #sqrt_w = tf.abs(label[2])\n",
    "    #sqrt_h = tf.abs(label[3])\n",
    "\n",
    "    #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    p_x = predict_boxes[:, :, :, 0]\n",
    "    p_y = predict_boxes[:, :, :, 1]\n",
    "\n",
    "\n",
    "    p_sqrt_w = tf.sqrt(tf.minimum(image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\n",
    "    p_sqrt_h = tf.sqrt(tf.minimum(image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n",
    "    #calculate truth p 1-D tensor [NUM_CLASSES]\n",
    "    P = tf.one_hot(tf.cast(label[4], tf.int32), num_classes, dtype=tf.float32)\n",
    "\n",
    "    #calculate predict p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\n",
    "    p_P = predict[:, :, 0:num_classes]\n",
    "\n",
    "    #class_loss\n",
    "    class_loss = tf.nn.l2_loss(tf.reshape(objects, (cell_size, cell_size, 1)) * (p_P - P)) * class_scale\n",
    "    #class_loss = tf.nn.l2_loss(tf.reshape(response, (cell_size, cell_size, 1)) * (p_P - P)) * class_scale\n",
    "\n",
    "    #object_loss\n",
    "    object_loss = tf.nn.l2_loss(I * (p_C - C)) * object_scale\n",
    "\n",
    "    #noobject_loss\n",
    "    noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * noobject_scale\n",
    "\n",
    "    #coord_loss\n",
    "    coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(image_size/cell_size)) +\n",
    "                 tf.nn.l2_loss(I * (p_y - y)/(image_size/cell_size)) +\n",
    "                 tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/ image_size +\n",
    "                 tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/image_size) * coord_scale\n",
    "\n",
    "    nilboy = I\n",
    "\n",
    "    with tf.Session() as sess1:\n",
    "        print(\"第幾個標記框\",sess1.run(num))\n",
    "        #print(sess1.run(num)) \n",
    "        print(sess1.run(label)) \n",
    "        print(\"class_loss =\",sess1.run(class_loss))\n",
    "        print(\"object_loss=\",sess1.run(object_loss))\n",
    "        print(\"noobject_loss=\",sess1.run(noobject_loss))\n",
    "        print(\"coord_loss=\",sess1.run(coord_loss))\n",
    "    return num + 1, object_num, [loss[0] + class_loss, loss[1] + object_loss, loss[2] + noobject_loss, loss[3] + coord_loss], predict, labels, nilboy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgHRoc3rbFVf"
   },
   "outputs": [],
   "source": [
    "def loss(predicts, labels, objects_num):\n",
    "    \"\"\"Add Loss to all the trainable variables\n",
    "\n",
    "    Args:\n",
    "      predicts: 4-D tensor [batch_size, cell_size, cell_size, 5 * boxes_per_cell]\n",
    "      ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\n",
    "      labels  : 3-D tensor of [batch_size, max_objects, 5]\n",
    "      objects_num: 1-D tensor [batch_size]\n",
    "    \"\"\"\n",
    "    print(\"loss\")\n",
    "    class_loss = tf.constant(0, tf.float32) #bbox物件類別計算損失\n",
    "    object_loss = tf.constant(0, tf.float32) #bbox 物件信心度計算損失\n",
    "    noobject_loss = tf.constant(0, tf.float32) #bbox 無物件信心度計算損失\n",
    "    coord_loss = tf.constant(0, tf.float32) #bbox的定位計算損失\n",
    "    loss = [0, 0, 0, 0]\n",
    "    #每一張圖都各自計算 loss\n",
    "    for i in range(batch_size):\n",
    "      predict = predicts[i, :, :, :]\n",
    "      #print(\"predict==\",predicts.shape.as_list())\n",
    "      label = labels[i, :, :]\n",
    "      object_num = objects_num[i]\n",
    "      nilboy = tf.ones([7,7,2])\n",
    "      #以每一個標記框分別計算每一張圖是否有那一個物件，進行損失函數的運算\n",
    "      tuple_results = body1(tf.constant(0), object_num, [class_loss, object_loss, noobject_loss, coord_loss], predict, label, nilboy)\n",
    "      for j in range(4):\n",
    "        loss[j] = loss[j] + tuple_results[2][j]\n",
    "      tuple_results = body1(tf.constant(1), object_num, [class_loss, object_loss, noobject_loss, coord_loss], predict, label, nilboy)\n",
    "  \n",
    "      for j in range(4):\n",
    "        loss[j] = loss[j] + tuple_results[2][j]\n",
    "      tuple_results = body1(tf.constant(2), object_num, [class_loss, object_loss, noobject_loss, coord_loss], predict, label, nilboy)\n",
    "     \n",
    "      for j in range(4):\n",
    "        loss[j] = loss[j] + tuple_results[2][j]\n",
    "      nilboy = tuple_results[5]\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ARNv7PLmbFVl"
   },
   "source": [
    "### 計算標記框和預測框的loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11627,
     "status": "ok",
     "timestamp": 1578970928124,
     "user": {
      "displayName": "Mora chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB40f7sDArbZ5_DYq02nNcnLD0Ryaf7AhsASSQeLQ=s64",
      "userId": "03171203089166907199"
     },
     "user_tz": -480
    },
    "id": "cAUyFiKmbFVn",
    "outputId": "416f5fc1-5522-4002-8ec5-67d301dadb60"
   },
   "outputs": [],
   "source": [
    "predicts=tf.reshape(np_predict,(1, 7, 7, 30))\n",
    "labels=tf.reshape(labels, (1,3, 5))\n",
    "#output_loss=net.loss(predicts, labels,  tf.constant(3, shape=[1]))\n",
    "output_loss=loss(predicts, labels,  tf.constant(3, shape=[1]))\n",
    "print(\"預測結果和標記框的損失量\")\n",
    "with tf.Session() as sess1: \n",
    "    print(sess1.run(output_loss)) \n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JG0RjWTRaK80"
   },
   "source": [
    "##  這個範例程式碼中的函數,為了要呈現損失函數的結果有些微調，有興趣想更深入了解的同學，可以透過Sublime Text軟體，開啟資料夾\\yolo\\net\\yolo\\yolo_net.py的程式碼。\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day35_yolo_loss.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
